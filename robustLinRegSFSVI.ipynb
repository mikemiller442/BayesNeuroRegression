{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2950609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "from torch.nn.utils.parametrizations import _Orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539cf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined model class that inherits from Pytorch's neural network module\n",
    "# NumComponents is the number of low rank components to use in the low rank\n",
    "# part of the diagonal plus low rank covariance matrix.\n",
    "# numCESamples is the number of stochastic samples of the cross entropy\n",
    "# numNLLSamples is the number of stochastic samples of the negative log likelihood.\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,trainX,testX,trainY,testY,numComponents,numCESamples,numNLLSamples,xiVal):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input data\n",
    "        self.X = trainX\n",
    "        self.testX = testX\n",
    "        self.Y = trainY\n",
    "        self.testY = testY\n",
    "        self.trainN = self.Y.size(dim=0)\n",
    "        self.testN = self.testY.size(dim=0)\n",
    "        self.nw = self.X.size(dim=1)\n",
    "        self.nc = numComponents\n",
    "        self.ns = numCESamples\n",
    "        self.nsNLL = numNLLSamples\n",
    "        \n",
    "        # Regression parameter means\n",
    "        betaInit = torch.squeeze(torch.distributions.Uniform(-0.0001,0.0001).sample((1,self.nw)).double())\n",
    "        self.betaMu = nn.Parameter(betaInit)\n",
    "        self.scaleSqMu = nn.Parameter(torch.tensor([math.log(0.000025)-0.5,-0.5],dtype=torch.double))\n",
    "        self.xi = nn.Parameter(torch.tensor(xiVal,dtype=torch.double))\n",
    "        \n",
    "        # Diagonal component of parameter covariance\n",
    "        self.paramVar = nn.Parameter(torch.ones((self.nw+2),dtype=torch.double)*0.0001)\n",
    "        \n",
    "        # Low rank covariance of all parameters\n",
    "        self.V = nn.Parameter(torch.distributions.Uniform(-0.0001,0.0001).sample((self.nw+2,self.nc)).double())\n",
    "        \n",
    "        # Diagonal matrix of eigenvalues for low rank component\n",
    "        self.C = nn.Parameter(torch.ones(self.nc,dtype=torch.double)*-10.0)\n",
    "        \n",
    "        # Apply orthogonal parametrization to V\n",
    "        # Use householder reflections instead of the matrix exponential or Cayley map as householder\n",
    "        # reflections are computationally cheaper\n",
    "        parametrize.register_parametrization(self,\"V\", _Orthogonal(self.V, orthogonal_map=\"householder\"))\n",
    "        \n",
    "        # Scale parameter priors\n",
    "        self.lambdaPrior = torch.tensor(1.0,dtype=torch.double)\n",
    "        self.regVarPrior = torch.tensor(1.0,dtype=torch.double)\n",
    "        \n",
    "        # Training metrics\n",
    "        self.listTrainMSE = []\n",
    "        self.listTestMSE = []\n",
    "        self.listTrainR2 = []\n",
    "        self.listTestR2 = []\n",
    "        \n",
    "\n",
    "# Samples the weights wrt to the q density\n",
    "def sampleWeights(mod):\n",
    "    diagC = torch.diag(torch.exp(mod.C))\n",
    "    mod.paramCov = torch.diag(torch.exp(mod.paramVar)) + torch.matmul(torch.matmul(mod.V,diagC),torch.transpose(mod.V,0,1))\n",
    "    lsCov = mod.paramCov[0:2,0:2]\n",
    "     \n",
    "    predWeights = 0.0\n",
    "    for i in range(mod.ns):\n",
    "        \n",
    "        # Sample diagonal lambdaSq and sigmaSq\n",
    "        mod.stdNormalDistNP = torch.distributions.MultivariateNormal(mod.scaleSqMu, covariance_matrix = lsCov)\n",
    "        lsParams = mod.stdNormalDistNP.rsample()\n",
    "        # Sample weights\n",
    "        predBeta = (torch.unsqueeze(mod.betaMu,1) + torch.matmul(mod.paramCov[2:,0:2],\n",
    "                    torch.matmul(torch.inverse(lsCov),torch.unsqueeze(lsParams,1) - torch.unsqueeze(mod.scaleSqMu,1))))\n",
    "        scaleParams = torch.unsqueeze(torch.cat(((torch.unsqueeze(torch.tensor(1.0,dtype=torch.double),0)).clone(),\n",
    "                      torch.exp(0.5*mod.xi*lsParams[0])*torch.ones((mod.nw-1))),0),1)\n",
    "        predWeights = predWeights + torch.mul(predBeta,scaleParams)\n",
    "        \n",
    "    return (1.0/mod.ns)*predWeights\n",
    "\n",
    "\n",
    "# Calculates the negative log likelihood\n",
    "def NLL(mod,startBatch,endBatch):\n",
    "    diagC = torch.diag(torch.exp(mod.C))\n",
    "    diagC_sqrt = torch.diag(torch.sqrt(torch.exp(mod.C)))\n",
    "    mod.paramCov = torch.diag(torch.exp(mod.paramVar)) + torch.matmul(torch.matmul(mod.V,diagC),torch.transpose(mod.V,0,1))\n",
    "    lsCov = mod.paramCov[0:2,0:2]\n",
    "    \n",
    "#     K = (torch.eye(mod.nc) + torch.matmul(torch.matmul(torch.transpose(mod.V[0:2,:],0,1),\n",
    "#          torch.diag(torch.pow(torch.exp(mod.paramVar[0:2]),-1.0))),torch.matmul(mod.V[0:2,:],diagC)))\n",
    "    \n",
    "    K = (torch.diag(torch.pow(torch.exp(mod.C), -1.0))\n",
    "         + torch.matmul(torch.matmul(torch.transpose(mod.V[0:2,:],0,1),\n",
    "                                     torch.diag(torch.pow(torch.exp(mod.paramVar[0:2]),-1.0))),mod.V[0:2,:]))\n",
    "    \n",
    "    LK = torch.linalg.cholesky(K)\n",
    "    mod.stdNormalDistNP = torch.distributions.MultivariateNormal(mod.scaleSqMu,covariance_matrix = lsCov)\n",
    "    \n",
    "    nll = 0.0\n",
    "    for i in range(mod.nsNLL):\n",
    "        \n",
    "        # Sample diagonal lambdaSq and sigmaSq\n",
    "        lsParams = mod.stdNormalDistNP.rsample(sample_shape=torch.Size([endBatch-startBatch]))\n",
    "        \n",
    "        ### Calculate pre-activation distribution\n",
    "        # calculate mean beta conditional on sampled scale parameters\n",
    "        predBeta = (torch.unsqueeze(mod.betaMu,1) + torch.matmul(mod.paramCov[2:,0:2],\n",
    "                    torch.matmul(torch.inverse(lsCov),torch.transpose(lsParams,0,1)\n",
    "                 - torch.unsqueeze(mod.scaleSqMu,1).repeat(1,endBatch-startBatch))))\n",
    "        scaleData = torch.cat(((torch.unsqueeze(mod.X[startBatch:endBatch,0],1)).clone(),\n",
    "                    torch.unsqueeze(torch.exp(0.5*mod.xi*lsParams[:,0]),1)*mod.X[startBatch:endBatch,1:]),1)\n",
    "        predMu = torch.sum(torch.mul(torch.transpose(predBeta,0,1),scaleData),dim=1)\n",
    "        \n",
    "#         Y = torch.linalg.solve(torch.transpose(LK,0,1),torch.matmul(torch.matmul(torch.transpose(mod.V[0:2,:],0,1),\n",
    "#             torch.diag(torch.pow(torch.exp(mod.paramVar[0:2]),-1))),torch.matmul(torch.matmul(mod.V[0:2,:],diagC),\n",
    "#             torch.matmul(torch.transpose(mod.V[2:,:],0,1),torch.transpose(scaleData,0,1)))))\n",
    "        \n",
    "        Y = torch.linalg.solve(torch.transpose(LK,0,1),\n",
    "                               torch.matmul(torch.matmul(torch.matmul(torch.transpose(mod.V[0:2,:],0,1),\n",
    "                                                                      torch.diag(torch.pow(torch.exp(mod.paramVar[0:2]),-1))),\n",
    "                                                         torch.matmul(mod.V[0:2,:], diagC_sqrt)),\n",
    "                                            torch.matmul(torch.matmul(diagC_sqrt, torch.transpose(mod.V[2:,:],0,1)),\n",
    "                                                         torch.transpose(scaleData,0,1))))\n",
    "        \n",
    "        # Standard deviation calculation with updated low-rank component\n",
    "        # Use sqrt(C) instead of C when calculating standard deviation of pre-activations\n",
    "#         sdB = torch.sqrt(torch.sum(torch.square(torch.matmul(torch.diag(torch.exp(0.5*mod.paramVar[2:])),\n",
    "#               torch.transpose(scaleData,0,1))),dim=0)\n",
    "#             + torch.sum(torch.square(torch.matmul(torch.matmul(diagC_sqrt,torch.transpose(mod.V[2:,:],0,1)),\n",
    "#               torch.transpose(scaleData,0,1))),dim=0) - torch.sum(torch.square(Y),dim=0))\n",
    "        \n",
    "        # Term 1: ||A_β^{1/2} · scaleData^T||²\n",
    "        term1 = torch.sum(torch.square(torch.matmul(torch.diag(torch.exp(0.5*mod.paramVar[2:])),\n",
    "                                                    torch.transpose(scaleData,0,1))),dim=0)\n",
    "\n",
    "        # Term 2: ||Ṽ_β^T · scaleData^T||²\n",
    "        term2 = torch.sum(torch.square(torch.matmul(torch.matmul(diagC_sqrt,torch.transpose(mod.V[2:,:],0,1)),\n",
    "                                                    torch.transpose(scaleData,0,1))),dim=0)\n",
    "\n",
    "        # Term 3: -||A_Λ^{-1/2} · Ṽ_Λ · Ṽ_β^T · scaleData^T||²\n",
    "        temp3 = torch.matmul(torch.matmul(diagC_sqrt,torch.transpose(mod.V[2:,:],0,1)),\n",
    "                             torch.transpose(scaleData,0,1))  # Ṽ_β^T · scaleData^T\n",
    "        temp3 = torch.matmul(torch.matmul(mod.V[0:2,:],diagC_sqrt),temp3)  # Ṽ_Λ · Ṽ_β^T · scaleData^T\n",
    "        temp3 = torch.matmul(torch.diag(torch.pow(torch.exp(mod.paramVar[0:2]),-0.5)),temp3)  # A_Λ^{-1/2} · ...\n",
    "        term3 = torch.sum(torch.square(temp3),dim=0)\n",
    "\n",
    "        # Term 4: +||Y||²\n",
    "        term4 = torch.sum(torch.square(Y), dim=0)\n",
    "\n",
    "        # Combine: note the signs!\n",
    "        sdB = torch.sqrt(term1 + term2 - term3 + term4)\n",
    "        \n",
    "        # Sample pre-activation and calculate negative log-likelihood\n",
    "        mod.stdNormalDistB = torch.distributions.Normal(predMu,sdB)\n",
    "        sampleB = mod.stdNormalDistB.rsample()\n",
    "        trainResiduals = mod.Y[startBatch:endBatch,:] - torch.unsqueeze(sampleB,1)\n",
    "        SE = torch.square(trainResiduals)\n",
    "        # Calculate log likelihood\n",
    "        nll = (nll + torch.sum(torch.mul(0.5*torch.unsqueeze(torch.exp(-1.0*lsParams[:,1]),1),SE)\n",
    "            + 0.5*(math.log(2.0*math.pi) + torch.unsqueeze(lsParams[:,1],1))))\n",
    "        \n",
    "    return (1.0/mod.nsNLL)*nll\n",
    "\n",
    "\n",
    "# Calculates the cross entropy\n",
    "def crossEntropy(mod):\n",
    "        \n",
    "    ## Sample all parameters together\n",
    "    mod.stdNormalDistNS1 = torch.distributions.Normal(torch.zeros((mod.ns,mod.nw+2),dtype=torch.double),\n",
    "                                                      torch.ones((mod.ns,mod.nw+2),dtype=torch.double))\n",
    "    mod.stdNormalDistNS2 = torch.distributions.Normal(torch.zeros((mod.nc),dtype=torch.double),\n",
    "                                                      torch.ones((mod.nc),dtype=torch.double))\n",
    "    \n",
    "    # Sample all parameters with C matrix - VECTORIZED\n",
    "    diagC_sqrt = torch.sqrt(torch.exp(mod.C))\n",
    "\n",
    "    # Sample diagonal component\n",
    "    paramSample = torch.mul(torch.sqrt(torch.exp(mod.paramVar)), mod.stdNormalDistNS1.sample())\n",
    "\n",
    "    # Sample low-rank component (vectorized)\n",
    "    z2_samples = mod.stdNormalDistNS2.sample(sample_shape=torch.Size([mod.ns]))\n",
    "    lowrank_component = torch.matmul(mod.V, torch.mul(diagC_sqrt.unsqueeze(1), z2_samples.T))\n",
    "    paramSample = paramSample + lowrank_component.T\n",
    "    \n",
    "    ceVal = 0.0\n",
    "    \n",
    "    # Calculate log prior density of lambdaSq multiplied by Jacobian determinant\n",
    "    sampledLambda = torch.exp(0.5*(mod.scaleSqMu[0] + paramSample[:,0]))\n",
    "    ceVal = (ceVal + (-1.0/mod.ns)*torch.sum(torch.log(torch.mul(0.5*sampledLambda,\n",
    "            ((2.0/(math.pi)))/(1.0 + torch.square(sampledLambda))))))\n",
    "    \n",
    "    # Calculate log prior density of sigmaSq multiplied by Jacobian determinant\n",
    "    sampledSigma = torch.exp(mod.scaleSqMu[1] + paramSample[:,1])\n",
    "    ceVal = (ceVal + (-1.0/mod.ns)*torch.sum(torch.log(torch.mul(sampledSigma,\n",
    "            ((2.0/(math.pi)))/(1.0 + torch.square(sampledSigma))))))\n",
    "    \n",
    "    # Calculate log prior density of bias\n",
    "    sampledBeta = mod.betaMu[0] + paramSample[:,2]\n",
    "    ceVal = ceVal + (-1.0/mod.ns)*torch.sum(-0.5*torch.square(sampledBeta))\n",
    "    ceVal = ceVal + (-1.0/mod.ns)*(-1.0*mod.ns)*0.5*math.log(2.0*math.pi)\n",
    "    \n",
    "    # Calculate log prior density of regression coefficients\n",
    "    sampledLambda = torch.exp((1.0-mod.xi)*(mod.scaleSqMu[0] + paramSample[:,0]))\n",
    "    sampledBeta = mod.betaMu[1:].repeat(mod.ns,1) + paramSample[:,3:]\n",
    "    priorVar = torch.unsqueeze(sampledLambda*sampledSigma,1).repeat(1,mod.nw-1)\n",
    "    ceVal = (ceVal + (-1.0/mod.ns)*torch.sum(torch.mul(-0.5*torch.square(sampledBeta),\n",
    "             torch.pow(priorVar,-1.0))))\n",
    "    ceVal = (ceVal + (-1.0/mod.ns)*torch.sum(-0.5*(mod.nw-1)*(math.log(2.0*math.pi)\n",
    "          + torch.log(sampledLambda*sampledSigma))))\n",
    "    \n",
    "    return ceVal\n",
    "\n",
    "\n",
    "# Calculates the entropy\n",
    "def entropy(mod):\n",
    "    diagC = torch.diag(torch.exp(mod.C))\n",
    "    entVal = (0.5*(mod.nw+2) + 0.5*(mod.nw+2)*math.log(2.0*math.pi) + 0.5*torch.sum(mod.paramVar)\n",
    "           + 0.5*torch.logdet(torch.eye(mod.nc) + torch.matmul(torch.matmul(torch.transpose(mod.V,0,1),\n",
    "             torch.diag(torch.pow(torch.exp(mod.paramVar),-1.0))),torch.matmul(mod.V, diagC)))\n",
    "           + 0.5*torch.sum(mod.C))\n",
    "    return entVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08811529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the linear model using Stochastic Variational Inference\n",
    "# maxEpochs is the maximum number of training epochs to use\n",
    "def trainModel(mod,opt,maxEpochs,batchSize,intervalToPrint):\n",
    "    numBatches = math.floor(mod.Y.size(dim=0)/batchSize)\n",
    "    trainN = mod.Y.size(dim=0)\n",
    "    testN = mod.testY.size(dim=0)\n",
    "    tol = 0.0\n",
    "    nelboIdx = 0\n",
    "    nelboList = []\n",
    "    nllList = []\n",
    "    klList = []\n",
    "    nelboList.append(sys.float_info.max)\n",
    "    nllList.append(sys.float_info.max)\n",
    "    klList.append(sys.float_info.max)\n",
    "    for epoch in range(maxEpochs):\n",
    "        idx = torch.randperm(mod.Y.size(dim=0))\n",
    "        mod.Y = mod.Y[idx].view(mod.Y.shape)\n",
    "        mod.X = mod.X[idx].view(mod.X.shape)\n",
    "        for batch in range(numBatches):\n",
    "            opt.zero_grad()\n",
    "            NLLval = (1.0/batchSize)*NLL(mod,batch*batchSize,(batch + 1)*batchSize)\n",
    "            entVal = (1.0/trainN)*entropy(mod)\n",
    "            ceVal = (1.0/trainN)*crossEntropy(mod)\n",
    "            loss = NLLval + ceVal - entVal\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                mod.xi.clamp_(min = 0.0)\n",
    "                mod.xi.clamp_(max = 1.0)\n",
    "        if (epoch % intervalToPrint == 0):\n",
    "            with torch.no_grad():\n",
    "                NLLval = NLL(mod,0,trainN)\n",
    "                entVal = entropy(mod)\n",
    "                ceVal = crossEntropy(mod)\n",
    "                priorKL = ceVal - entVal\n",
    "                trainNELBO = NLLval + priorKL\n",
    "                nelboList.append(trainNELBO)\n",
    "                nllList.append(NLLval)\n",
    "                klList.append(priorKL)\n",
    "                nelboIdx = nelboIdx + 1\n",
    "                weights = sampleWeights(mod)\n",
    "                predTrainY = torch.matmul(mod.X,weights)\n",
    "                predTestY = torch.matmul(mod.testX,weights)\n",
    "                trainMSE = torch.mean(torch.square(mod.Y - predTrainY))\n",
    "                testMSE = torch.mean(torch.square(mod.testY - predTestY))\n",
    "                \n",
    "            print('Epoch {}, Neg Train ELBO {}, PriorKL {}, Train MSE {}, Test MSE {}'.format(epoch,trainNELBO,priorKL,trainMSE,testMSE))\n",
    "            # Calculate marginal variances using diagonal plus low rank covariance structure\n",
    "            marginalVar = torch.exp(mod.paramVar) + torch.sum(torch.square(mod.V)*torch.exp(mod.C).unsqueeze(0),dim=1)\n",
    "            print('Lambda Sq: {:.4e}'.format(torch.exp(mod.scaleSqMu[0] + 0.5*marginalVar[0])))\n",
    "            print('Sigma Sq: {:.4f}'.format(torch.exp(mod.scaleSqMu[1] + 0.5*marginalVar[1])))\n",
    "            print(mod.xi)\n",
    "            \n",
    "    return mod, nelboList, nllList, klList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f613d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2700, 1772])\n",
      "torch.Size([300, 1772])\n",
      "torch.Size([2700, 1])\n",
      "torch.Size([300, 1])\n",
      "Training size: 2700\n",
      "Testing size: 300\n",
      "tensor(1.1458, dtype=torch.float64)\n",
      "tensor(1.1787, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = pd.read_csv(\"trainImagingFeatures.csv\", index_col = False)\n",
    "trainFeatures = trainFeatures.drop(trainFeatures.columns[0], axis = 1)\n",
    "trainFeatures = torch.tensor(trainFeatures.values, dtype = torch.double)\n",
    "trainFeatures = torch.cat((torch.ones((trainFeatures.size(dim=0),1)),trainFeatures),1)\n",
    "\n",
    "testFeatures = pd.read_csv(\"testImagingFeatures.csv\", index_col = False)\n",
    "testFeatures = testFeatures.drop(testFeatures.columns[0], axis = 1)\n",
    "testFeatures = torch.tensor(testFeatures.values, dtype = torch.double)\n",
    "testFeatures = torch.cat((torch.ones((testFeatures.size(dim=0),1)),testFeatures),1)\n",
    "\n",
    "trainResponse = pd.read_csv(\"train_y_residualized.csv\", index_col = False)\n",
    "trainResponse = trainResponse.drop(trainResponse.columns[0], axis = 1)\n",
    "trainResponse = torch.tensor(trainResponse.values, dtype = torch.double)\n",
    "\n",
    "testResponse = pd.read_csv(\"test_y_residualized.csv\", index_col = False)\n",
    "testResponse = testResponse.drop(testResponse.columns[0], axis = 1)\n",
    "testResponse = torch.tensor(testResponse.values, dtype = torch.double)\n",
    "\n",
    "print(trainFeatures.shape)\n",
    "print(testFeatures.shape)\n",
    "print(trainResponse.shape)\n",
    "print(testResponse.shape)\n",
    "\n",
    "print(f\"Training size: {trainFeatures.shape[0]}\")\n",
    "print(f\"Testing size: {testFeatures.shape[0]}\")\n",
    "\n",
    "print(torch.std(trainResponse))\n",
    "print(torch.std(testResponse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3ab9c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Neg Train ELBO 20288.542787008315, PriorKL 494.4406257456494, Train MSE 1.363782214889798, Test MSE 1.4929660811742518\n",
      "Lambda Sq: 1.7747e-05\n",
      "Sigma Sq: 1.1463\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 1, Neg Train ELBO 12180.761135040897, PriorKL 433.5314441017449, Train MSE 1.2856789693633868, Test MSE 1.3957823835584353\n",
      "Lambda Sq: 1.3780e-05\n",
      "Sigma Sq: 1.3030\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 2, Neg Train ELBO 9688.45430742906, PriorKL 343.35170319795657, Train MSE 1.2355012337433129, Test MSE 1.3685945697974877\n",
      "Lambda Sq: 1.1587e-05\n",
      "Sigma Sq: 1.4467\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 3, Neg Train ELBO 8037.961411497241, PriorKL 389.9760538401838, Train MSE 1.2250775996489203, Test MSE 1.390805841350111\n",
      "Lambda Sq: 1.0216e-05\n",
      "Sigma Sq: 1.5685\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 4, Neg Train ELBO 7389.814777657899, PriorKL 439.25076796160147, Train MSE 1.2151449821894715, Test MSE 1.3670263754844791\n",
      "Lambda Sq: 9.3261e-06\n",
      "Sigma Sq: 1.6639\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 5, Neg Train ELBO 6791.470418495262, PriorKL 411.3951297207375, Train MSE 1.1827011340399625, Test MSE 1.285766439889401\n",
      "Lambda Sq: 8.6722e-06\n",
      "Sigma Sq: 1.7410\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 6, Neg Train ELBO 6499.00821548177, PriorKL 454.0764033015953, Train MSE 1.1662574488264577, Test MSE 1.2983773080062395\n",
      "Lambda Sq: 8.1736e-06\n",
      "Sigma Sq: 1.8017\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 7, Neg Train ELBO 6446.252730128608, PriorKL 440.3103056103141, Train MSE 1.1681470815521726, Test MSE 1.292459667856926\n",
      "Lambda Sq: 7.7822e-06\n",
      "Sigma Sq: 1.8496\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 8, Neg Train ELBO 6130.400679540291, PriorKL 440.2641685528142, Train MSE 1.1597628079743318, Test MSE 1.2818962863486687\n",
      "Lambda Sq: 7.4428e-06\n",
      "Sigma Sq: 1.8905\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 9, Neg Train ELBO 6069.993738044309, PriorKL 442.14930443359026, Train MSE 1.1568413218860656, Test MSE 1.2790465255379393\n",
      "Lambda Sq: 7.1454e-06\n",
      "Sigma Sq: 1.9240\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 10, Neg Train ELBO 5936.691405084334, PriorKL 439.15821642408446, Train MSE 1.15910357630906, Test MSE 1.285550890525426\n",
      "Lambda Sq: 6.8722e-06\n",
      "Sigma Sq: 1.9523\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 11, Neg Train ELBO 5819.566540274725, PriorKL 438.67696575438185, Train MSE 1.1505466067168764, Test MSE 1.2694053325268129\n",
      "Lambda Sq: 6.6235e-06\n",
      "Sigma Sq: 1.9765\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 12, Neg Train ELBO 5593.2541331638, PriorKL 396.3713653207765, Train MSE 1.1437967573736074, Test MSE 1.273327961668349\n",
      "Lambda Sq: 6.3951e-06\n",
      "Sigma Sq: 1.9956\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 13, Neg Train ELBO 5642.306706775522, PriorKL 419.34883324347265, Train MSE 1.1509766027589343, Test MSE 1.2676014044956008\n",
      "Lambda Sq: 6.1793e-06\n",
      "Sigma Sq: 2.0112\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 14, Neg Train ELBO 5517.989177203404, PriorKL 411.5218783120067, Train MSE 1.139131083527857, Test MSE 1.2442270256374566\n",
      "Lambda Sq: 5.9777e-06\n",
      "Sigma Sq: 2.0242\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 15, Neg Train ELBO 5419.855534167812, PriorKL 353.6590707075384, Train MSE 1.1423860414254166, Test MSE 1.2728521127883163\n",
      "Lambda Sq: 5.7822e-06\n",
      "Sigma Sq: 2.0345\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 16, Neg Train ELBO 5388.163521517715, PriorKL 377.10368342777747, Train MSE 1.138000824382188, Test MSE 1.2673893642865337\n",
      "Lambda Sq: 5.6055e-06\n",
      "Sigma Sq: 2.0420\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 17, Neg Train ELBO 5419.168723383422, PriorKL 375.14308017929807, Train MSE 1.1347254586925255, Test MSE 1.2561380571586804\n",
      "Lambda Sq: 5.4437e-06\n",
      "Sigma Sq: 2.0437\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 18, Neg Train ELBO 5372.842961585782, PriorKL 346.5558437377931, Train MSE 1.1414645179531757, Test MSE 1.2675687779876417\n",
      "Lambda Sq: 5.2831e-06\n",
      "Sigma Sq: 2.0457\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 19, Neg Train ELBO 5201.983805607762, PriorKL 317.77449607117705, Train MSE 1.1363994522792598, Test MSE 1.2492043223695275\n",
      "Lambda Sq: 5.1299e-06\n",
      "Sigma Sq: 2.0459\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 20, Neg Train ELBO 5249.327302412155, PriorKL 315.1381216068362, Train MSE 1.1277731050433926, Test MSE 1.238258436909662\n",
      "Lambda Sq: 4.9860e-06\n",
      "Sigma Sq: 2.0433\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 21, Neg Train ELBO 5157.655224993665, PriorKL 314.2597590571745, Train MSE 1.1303686246437525, Test MSE 1.244384419685715\n",
      "Lambda Sq: 4.8483e-06\n",
      "Sigma Sq: 2.0390\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 22, Neg Train ELBO 5152.494133009484, PriorKL 294.6025058231339, Train MSE 1.1234287178454279, Test MSE 1.2371140348330678\n",
      "Lambda Sq: 4.7194e-06\n",
      "Sigma Sq: 2.0302\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 23, Neg Train ELBO 5157.53554476353, PriorKL 310.9326970187999, Train MSE 1.1257697869812597, Test MSE 1.2420266011258256\n",
      "Lambda Sq: 4.5912e-06\n",
      "Sigma Sq: 2.0224\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 24, Neg Train ELBO 5080.225025952499, PriorKL 306.5258298292829, Train MSE 1.1338852859521904, Test MSE 1.2535492712046652\n",
      "Lambda Sq: 4.4699e-06\n",
      "Sigma Sq: 2.0117\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 25, Neg Train ELBO 5083.332976817239, PriorKL 323.15640853810874, Train MSE 1.1241135766914807, Test MSE 1.2383857270544667\n",
      "Lambda Sq: 4.3583e-06\n",
      "Sigma Sq: 1.9981\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 26, Neg Train ELBO 5011.7125953535215, PriorKL 261.5938967412221, Train MSE 1.124658220005019, Test MSE 1.239995888135425\n",
      "Lambda Sq: 4.2497e-06\n",
      "Sigma Sq: 1.9863\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 27, Neg Train ELBO 4966.470606755833, PriorKL 262.9568896177957, Train MSE 1.1243158784461957, Test MSE 1.2428543135464656\n",
      "Lambda Sq: 4.1444e-06\n",
      "Sigma Sq: 1.9730\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 28, Neg Train ELBO 4975.572201092977, PriorKL 260.6903434993351, Train MSE 1.1217877476033187, Test MSE 1.2310593509149066\n",
      "Lambda Sq: 4.0400e-06\n",
      "Sigma Sq: 1.9610\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 29, Neg Train ELBO 5017.677667954202, PriorKL 252.6595733620493, Train MSE 1.1206764804219653, Test MSE 1.2260170727683821\n",
      "Lambda Sq: 3.9356e-06\n",
      "Sigma Sq: 1.9499\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 30, Neg Train ELBO 4960.5040302371945, PriorKL 244.02646706967744, Train MSE 1.125947660044776, Test MSE 1.244716098551495\n",
      "Lambda Sq: 3.8365e-06\n",
      "Sigma Sq: 1.9356\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 31, Neg Train ELBO 4928.074943095346, PriorKL 262.43363971112694, Train MSE 1.1154013512088532, Test MSE 1.2298348572162383\n",
      "Lambda Sq: 3.7457e-06\n",
      "Sigma Sq: 1.9189\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 32, Neg Train ELBO 4859.048698530327, PriorKL 228.08514516154946, Train MSE 1.1149230591205685, Test MSE 1.2293690255768424\n",
      "Lambda Sq: 3.6560e-06\n",
      "Sigma Sq: 1.9009\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 33, Neg Train ELBO 4911.6416798049795, PriorKL 243.89610589333324, Train MSE 1.1173887338611954, Test MSE 1.2366756215232313\n",
      "Lambda Sq: 3.5681e-06\n",
      "Sigma Sq: 1.8847\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Neg Train ELBO 4834.790846381227, PriorKL 240.86625766548104, Train MSE 1.1156409387732793, Test MSE 1.2347283153127615\n",
      "Lambda Sq: 3.4853e-06\n",
      "Sigma Sq: 1.8677\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 35, Neg Train ELBO 4874.762756218592, PriorKL 222.91848758413198, Train MSE 1.1187860066730753, Test MSE 1.230432081177124\n",
      "Lambda Sq: 3.4023e-06\n",
      "Sigma Sq: 1.8519\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 36, Neg Train ELBO 4789.906200687135, PriorKL 215.2807604764639, Train MSE 1.1154293512732247, Test MSE 1.225597430866027\n",
      "Lambda Sq: 3.3253e-06\n",
      "Sigma Sq: 1.8345\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 37, Neg Train ELBO 4797.832420676283, PriorKL 225.18075870510393, Train MSE 1.1167834149629352, Test MSE 1.2280243556820076\n",
      "Lambda Sq: 3.2489e-06\n",
      "Sigma Sq: 1.8175\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 38, Neg Train ELBO 4754.123428590379, PriorKL 207.1578511949865, Train MSE 1.1184556479230268, Test MSE 1.2348936779292934\n",
      "Lambda Sq: 3.1752e-06\n",
      "Sigma Sq: 1.8011\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 39, Neg Train ELBO 4728.944472331514, PriorKL 204.03731556143657, Train MSE 1.1150098426951014, Test MSE 1.2229023415913198\n",
      "Lambda Sq: 3.1080e-06\n",
      "Sigma Sq: 1.7827\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 40, Neg Train ELBO 4763.496123088717, PriorKL 203.3831890125134, Train MSE 1.110420966009466, Test MSE 1.2263463846870033\n",
      "Lambda Sq: 3.0401e-06\n",
      "Sigma Sq: 1.7666\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 41, Neg Train ELBO 4701.083986028815, PriorKL 201.10791203760618, Train MSE 1.1188616572046601, Test MSE 1.2402199044550135\n",
      "Lambda Sq: 2.9739e-06\n",
      "Sigma Sq: 1.7527\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 42, Neg Train ELBO 4739.49318456608, PriorKL 186.13293998636982, Train MSE 1.1147362494905042, Test MSE 1.2316431181103353\n",
      "Lambda Sq: 2.9128e-06\n",
      "Sigma Sq: 1.7357\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 43, Neg Train ELBO 4699.176847312938, PriorKL 194.8470343562608, Train MSE 1.1126805236293353, Test MSE 1.2254279367539311\n",
      "Lambda Sq: 2.8491e-06\n",
      "Sigma Sq: 1.7183\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 44, Neg Train ELBO 4663.262781478535, PriorKL 183.81761072217978, Train MSE 1.1138100668558413, Test MSE 1.2314807192687234\n",
      "Lambda Sq: 2.7878e-06\n",
      "Sigma Sq: 1.7026\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 45, Neg Train ELBO 4704.261601301321, PriorKL 192.04779429223026, Train MSE 1.1102417707668926, Test MSE 1.2280400976421264\n",
      "Lambda Sq: 2.7249e-06\n",
      "Sigma Sq: 1.6874\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 46, Neg Train ELBO 4663.684997293818, PriorKL 181.40165042580293, Train MSE 1.1136234975801307, Test MSE 1.236869730119627\n",
      "Lambda Sq: 2.6677e-06\n",
      "Sigma Sq: 1.6723\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 47, Neg Train ELBO 4675.884898966418, PriorKL 181.07082536814232, Train MSE 1.1076052653373456, Test MSE 1.225714180817202\n",
      "Lambda Sq: 2.6131e-06\n",
      "Sigma Sq: 1.6558\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 48, Neg Train ELBO 4591.904946485444, PriorKL 169.0595655488296, Train MSE 1.1085992638477922, Test MSE 1.222765615034433\n",
      "Lambda Sq: 2.5619e-06\n",
      "Sigma Sq: 1.6395\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 49, Neg Train ELBO 4621.879346933845, PriorKL 179.38595698159907, Train MSE 1.1051438216986347, Test MSE 1.217070560083915\n",
      "Lambda Sq: 2.5100e-06\n",
      "Sigma Sq: 1.6262\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "intervalToPrint = 1\n",
    "batchSize = 256\n",
    "numComponents = 16\n",
    "numCESamples = 128\n",
    "numNLLSamples = 2\n",
    "xiVal = 1.0\n",
    "\n",
    "# initialize model\n",
    "model = Model(trainFeatures,testFeatures,trainResponse,testResponse,numComponents,numCESamples,numNLLSamples,xiVal)\n",
    "\n",
    "# first train at low batch size\n",
    "maxEpochs = 50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.025)\n",
    "model, nelboList, nllList, klList = trainModel(model,optimizer,maxEpochs,batchSize,intervalToPrint)\n",
    "\n",
    "# Save\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'nelboList': nelboList,\n",
    "    'nllList': nllList,\n",
    "    'klList': klList\n",
    "}, 'model_and_metrics.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e4089d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Neg Train ELBO 4147.082245518507, PriorKL 84.04382353108622, Train MSE 1.0978926517934993, Test MSE 1.2003623815941837\n",
      "Lambda Sq: 4.4965e-07\n",
      "Sigma Sq: 1.1802\n",
      "Parameter containing:\n",
      "tensor(0.9936, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 1, Neg Train ELBO 4131.212215905014, PriorKL 81.63837020289111, Train MSE 1.101508227322456, Test MSE 1.2068455531366562\n",
      "Lambda Sq: 4.4975e-07\n",
      "Sigma Sq: 1.1769\n",
      "Parameter containing:\n",
      "tensor(0.9969, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 2, Neg Train ELBO 4140.45716872624, PriorKL 84.84582111286409, Train MSE 1.1000410661468527, Test MSE 1.1969576987021988\n",
      "Lambda Sq: 4.4652e-07\n",
      "Sigma Sq: 1.1744\n",
      "Parameter containing:\n",
      "tensor(0.9929, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 3, Neg Train ELBO 4141.616212335785, PriorKL 83.82047883943324, Train MSE 1.1056672289015876, Test MSE 1.20926620129441\n",
      "Lambda Sq: 4.4190e-07\n",
      "Sigma Sq: 1.1790\n",
      "Parameter containing:\n",
      "tensor(0.9981, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 4, Neg Train ELBO 4136.000930756947, PriorKL 81.14117364881668, Train MSE 1.1002726399378786, Test MSE 1.2013920731824945\n",
      "Lambda Sq: 4.3975e-07\n",
      "Sigma Sq: 1.1798\n",
      "Parameter containing:\n",
      "tensor(0.9955, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 5, Neg Train ELBO 4146.32114376316, PriorKL 81.28484400587695, Train MSE 1.1003677723732586, Test MSE 1.2031654569920165\n",
      "Lambda Sq: 4.3724e-07\n",
      "Sigma Sq: 1.1814\n",
      "Parameter containing:\n",
      "tensor(0.9971, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 6, Neg Train ELBO 4132.806641801888, PriorKL 77.58143275516113, Train MSE 1.0991813616177486, Test MSE 1.199413853277045\n",
      "Lambda Sq: 4.3472e-07\n",
      "Sigma Sq: 1.1790\n",
      "Parameter containing:\n",
      "tensor(0.9955, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 7, Neg Train ELBO 4148.857615169996, PriorKL 81.29074385244803, Train MSE 1.1007101683271852, Test MSE 1.201662719640612\n",
      "Lambda Sq: 4.3285e-07\n",
      "Sigma Sq: 1.1798\n",
      "Parameter containing:\n",
      "tensor(0.9967, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 8, Neg Train ELBO 4141.460860699669, PriorKL 81.57836409641732, Train MSE 1.0983789486429625, Test MSE 1.1965545461952998\n",
      "Lambda Sq: 4.3046e-07\n",
      "Sigma Sq: 1.1831\n",
      "Parameter containing:\n",
      "tensor(0.9950, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 9, Neg Train ELBO 4145.508203835389, PriorKL 83.21733430502445, Train MSE 1.1002250559109263, Test MSE 1.202456938275785\n",
      "Lambda Sq: 4.2785e-07\n",
      "Sigma Sq: 1.1819\n",
      "Parameter containing:\n",
      "tensor(0.9959, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 10, Neg Train ELBO 4137.988431874159, PriorKL 82.92044560740214, Train MSE 1.0988163941986455, Test MSE 1.1983948578466508\n",
      "Lambda Sq: 4.2694e-07\n",
      "Sigma Sq: 1.1816\n",
      "Parameter containing:\n",
      "tensor(0.9945, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 11, Neg Train ELBO 4144.6489067593975, PriorKL 80.97232341684867, Train MSE 1.0983695526846176, Test MSE 1.2000879944264171\n",
      "Lambda Sq: 4.2534e-07\n",
      "Sigma Sq: 1.1804\n",
      "Parameter containing:\n",
      "tensor(0.9946, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 12, Neg Train ELBO 4125.2856588363575, PriorKL 82.5594256403815, Train MSE 1.1022329008325908, Test MSE 1.2049035343093124\n",
      "Lambda Sq: 4.2311e-07\n",
      "Sigma Sq: 1.1827\n",
      "Parameter containing:\n",
      "tensor(0.9974, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 13, Neg Train ELBO 4134.811051391091, PriorKL 83.19264203001285, Train MSE 1.1002186943018266, Test MSE 1.2033120472867507\n",
      "Lambda Sq: 4.2168e-07\n",
      "Sigma Sq: 1.1774\n",
      "Parameter containing:\n",
      "tensor(0.9949, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 14, Neg Train ELBO 4133.5635232429895, PriorKL 79.19132396048553, Train MSE 1.1010046508059284, Test MSE 1.2048277321975909\n",
      "Lambda Sq: 4.1864e-07\n",
      "Sigma Sq: 1.1754\n",
      "Parameter containing:\n",
      "tensor(0.9962, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 15, Neg Train ELBO 4141.209170054644, PriorKL 80.35151213348627, Train MSE 1.1002788198140772, Test MSE 1.197915866469301\n",
      "Lambda Sq: 4.1747e-07\n",
      "Sigma Sq: 1.1760\n",
      "Parameter containing:\n",
      "tensor(0.9963, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 16, Neg Train ELBO 4140.613119414978, PriorKL 82.41456037132048, Train MSE 1.1002536304303974, Test MSE 1.195928280258226\n",
      "Lambda Sq: 4.1528e-07\n",
      "Sigma Sq: 1.1784\n",
      "Parameter containing:\n",
      "tensor(0.9939, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 17, Neg Train ELBO 4150.08080401766, PriorKL 86.91062411797338, Train MSE 1.1080350498512255, Test MSE 1.2133913289887133\n",
      "Lambda Sq: 4.1221e-07\n",
      "Sigma Sq: 1.1799\n",
      "Parameter containing:\n",
      "tensor(0.9993, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 18, Neg Train ELBO 4127.644839066708, PriorKL 79.18892875484244, Train MSE 1.0989912830418114, Test MSE 1.1989702018519708\n",
      "Lambda Sq: 4.1069e-07\n",
      "Sigma Sq: 1.1764\n",
      "Parameter containing:\n",
      "tensor(0.9914, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 19, Neg Train ELBO 4117.906319955135, PriorKL 80.76844287483027, Train MSE 1.1021133906858704, Test MSE 1.2029741999695898\n",
      "Lambda Sq: 4.0871e-07\n",
      "Sigma Sq: 1.1790\n",
      "Parameter containing:\n",
      "tensor(0.9986, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 20, Neg Train ELBO 4137.16354779623, PriorKL 82.57123649862706, Train MSE 1.0991204957713312, Test MSE 1.1964368022606238\n",
      "Lambda Sq: 4.0682e-07\n",
      "Sigma Sq: 1.1769\n",
      "Parameter containing:\n",
      "tensor(0.9936, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 21, Neg Train ELBO 4145.2815716660325, PriorKL 83.86288829242085, Train MSE 1.0992498811587175, Test MSE 1.1991424364090613\n",
      "Lambda Sq: 4.0518e-07\n",
      "Sigma Sq: 1.1798\n",
      "Parameter containing:\n",
      "tensor(0.9950, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 22, Neg Train ELBO 4130.446721672423, PriorKL 78.17710461235401, Train MSE 1.103576874153591, Test MSE 1.207443006268604\n",
      "Lambda Sq: 4.0297e-07\n",
      "Sigma Sq: 1.1857\n",
      "Parameter containing:\n",
      "tensor(0.9957, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 23, Neg Train ELBO 4125.48083879938, PriorKL 77.04402402264031, Train MSE 1.1013290519024657, Test MSE 1.203846694026675\n",
      "Lambda Sq: 4.0053e-07\n",
      "Sigma Sq: 1.1816\n",
      "Parameter containing:\n",
      "tensor(0.9955, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 24, Neg Train ELBO 4135.3489475953575, PriorKL 78.13494266708994, Train MSE 1.0995971764354129, Test MSE 1.200147619494272\n",
      "Lambda Sq: 3.9835e-07\n",
      "Sigma Sq: 1.1777\n",
      "Parameter containing:\n",
      "tensor(0.9951, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 25, Neg Train ELBO 4146.11441791125, PriorKL 76.72071370764024, Train MSE 1.1017013196249068, Test MSE 1.2019070565508627\n",
      "Lambda Sq: 3.9686e-07\n",
      "Sigma Sq: 1.1786\n",
      "Parameter containing:\n",
      "tensor(0.9968, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 26, Neg Train ELBO 4138.40118868286, PriorKL 78.66017186822455, Train MSE 1.101106691617007, Test MSE 1.1974643615239147\n",
      "Lambda Sq: 3.9519e-07\n",
      "Sigma Sq: 1.1801\n",
      "Parameter containing:\n",
      "tensor(0.9941, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 27, Neg Train ELBO 4142.98321993681, PriorKL 85.93687480448489, Train MSE 1.1058975038687309, Test MSE 1.2085937697353548\n",
      "Lambda Sq: 3.9225e-07\n",
      "Sigma Sq: 1.1806\n",
      "Parameter containing:\n",
      "tensor(1.0000, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 28, Neg Train ELBO 4148.192371231375, PriorKL 83.89242924926566, Train MSE 1.1003853418728882, Test MSE 1.2018025488148898\n",
      "Lambda Sq: 3.9079e-07\n",
      "Sigma Sq: 1.1788\n",
      "Parameter containing:\n",
      "tensor(0.9939, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 29, Neg Train ELBO 4118.011478253054, PriorKL 74.8924679981028, Train MSE 1.1011487972195975, Test MSE 1.2012634520941476\n",
      "Lambda Sq: 3.8842e-07\n",
      "Sigma Sq: 1.1812\n",
      "Parameter containing:\n",
      "tensor(0.9961, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 30, Neg Train ELBO 4141.973679865933, PriorKL 81.56038422431538, Train MSE 1.1008424979508902, Test MSE 1.198746424948138\n",
      "Lambda Sq: 3.8661e-07\n",
      "Sigma Sq: 1.1822\n",
      "Parameter containing:\n",
      "tensor(0.9950, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 31, Neg Train ELBO 4123.023835146264, PriorKL 80.52684124864027, Train MSE 1.0997925664947685, Test MSE 1.1984969786374182\n",
      "Lambda Sq: 3.8502e-07\n",
      "Sigma Sq: 1.1836\n",
      "Parameter containing:\n",
      "tensor(0.9926, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 32, Neg Train ELBO 4107.766150258999, PriorKL 81.01651797520344, Train MSE 1.1017482847041526, Test MSE 1.2017565542084563\n",
      "Lambda Sq: 3.8490e-07\n",
      "Sigma Sq: 1.1772\n",
      "Parameter containing:\n",
      "tensor(0.9974, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 33, Neg Train ELBO 4128.783330693177, PriorKL 87.29047437050485, Train MSE 1.0996350627376126, Test MSE 1.197922286243123\n",
      "Lambda Sq: 3.8420e-07\n",
      "Sigma Sq: 1.1779\n",
      "Parameter containing:\n",
      "tensor(0.9961, dtype=torch.float64, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Neg Train ELBO 4145.788965278867, PriorKL 78.28092633097049, Train MSE 1.100824831286708, Test MSE 1.200830015701004\n",
      "Lambda Sq: 3.8206e-07\n",
      "Sigma Sq: 1.1714\n",
      "Parameter containing:\n",
      "tensor(0.9948, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 35, Neg Train ELBO 4135.328594891378, PriorKL 86.54782422943481, Train MSE 1.1068852046755453, Test MSE 1.2103106869325837\n",
      "Lambda Sq: 3.7969e-07\n",
      "Sigma Sq: 1.1750\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 36, Neg Train ELBO 4118.092805120903, PriorKL 79.46715916317862, Train MSE 1.10155609873059, Test MSE 1.2022439869178736\n",
      "Lambda Sq: 3.7851e-07\n",
      "Sigma Sq: 1.1696\n",
      "Parameter containing:\n",
      "tensor(0.9960, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 37, Neg Train ELBO 4116.12565418544, PriorKL 77.1464694055826, Train MSE 1.100730787612541, Test MSE 1.1989493110360439\n",
      "Lambda Sq: 3.7709e-07\n",
      "Sigma Sq: 1.1678\n",
      "Parameter containing:\n",
      "tensor(0.9954, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 38, Neg Train ELBO 4133.923499305107, PriorKL 75.7989264457974, Train MSE 1.1026071075892727, Test MSE 1.1987159510906613\n",
      "Lambda Sq: 3.7575e-07\n",
      "Sigma Sq: 1.1759\n",
      "Parameter containing:\n",
      "tensor(0.9963, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 39, Neg Train ELBO 4124.57365213694, PriorKL 75.23873349134101, Train MSE 1.101684033684869, Test MSE 1.1982744709624353\n",
      "Lambda Sq: 3.7453e-07\n",
      "Sigma Sq: 1.1698\n",
      "Parameter containing:\n",
      "tensor(0.9961, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 40, Neg Train ELBO 4133.351466257018, PriorKL 72.14047865026578, Train MSE 1.1016117349808354, Test MSE 1.195995394693029\n",
      "Lambda Sq: 3.7636e-07\n",
      "Sigma Sq: 1.1656\n",
      "Parameter containing:\n",
      "tensor(0.9947, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 41, Neg Train ELBO 4115.185490404448, PriorKL 77.5163827781098, Train MSE 1.1056397284796295, Test MSE 1.207307470012309\n",
      "Lambda Sq: 3.7200e-07\n",
      "Sigma Sq: 1.1679\n",
      "Parameter containing:\n",
      "tensor(0.9988, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 42, Neg Train ELBO 4127.992770132587, PriorKL 79.61006882082029, Train MSE 1.1020929351971784, Test MSE 1.203667139538405\n",
      "Lambda Sq: 3.7135e-07\n",
      "Sigma Sq: 1.1630\n",
      "Parameter containing:\n",
      "tensor(0.9971, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 43, Neg Train ELBO 4136.647692397155, PriorKL 81.88886619826053, Train MSE 1.1025215239604809, Test MSE 1.1979795327310638\n",
      "Lambda Sq: 3.6920e-07\n",
      "Sigma Sq: 1.1650\n",
      "Parameter containing:\n",
      "tensor(0.9926, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 44, Neg Train ELBO 4115.003757971868, PriorKL 79.26122865148909, Train MSE 1.1042509064314214, Test MSE 1.205858211238546\n",
      "Lambda Sq: 3.6717e-07\n",
      "Sigma Sq: 1.1744\n",
      "Parameter containing:\n",
      "tensor(0.9981, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 45, Neg Train ELBO 4115.560307584703, PriorKL 77.75990591893833, Train MSE 1.102059975448353, Test MSE 1.2026227315719782\n",
      "Lambda Sq: 3.6506e-07\n",
      "Sigma Sq: 1.1764\n",
      "Parameter containing:\n",
      "tensor(0.9971, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 46, Neg Train ELBO 4113.508954295521, PriorKL 77.89084169134685, Train MSE 1.1009218695162695, Test MSE 1.1989284337827317\n",
      "Lambda Sq: 3.6401e-07\n",
      "Sigma Sq: 1.1803\n",
      "Parameter containing:\n",
      "tensor(0.9965, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 47, Neg Train ELBO 4125.111112986604, PriorKL 76.10055492841911, Train MSE 1.1020014781964569, Test MSE 1.2022284750628813\n",
      "Lambda Sq: 3.6257e-07\n",
      "Sigma Sq: 1.1777\n",
      "Parameter containing:\n",
      "tensor(0.9959, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 48, Neg Train ELBO 4119.459691809226, PriorKL 78.89728963682865, Train MSE 1.1013579437073415, Test MSE 1.2002176715264992\n",
      "Lambda Sq: 3.6132e-07\n",
      "Sigma Sq: 1.1739\n",
      "Parameter containing:\n",
      "tensor(0.9958, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 49, Neg Train ELBO 4121.591781097469, PriorKL 79.14526639070391, Train MSE 1.1013121699830242, Test MSE 1.2003084577877159\n",
      "Lambda Sq: 3.5997e-07\n",
      "Sigma Sq: 1.1641\n",
      "Parameter containing:\n",
      "tensor(0.9955, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 50, Neg Train ELBO 4111.285189302893, PriorKL 79.28862132905533, Train MSE 1.104762542254262, Test MSE 1.205945103722893\n",
      "Lambda Sq: 3.5846e-07\n",
      "Sigma Sq: 1.1636\n",
      "Parameter containing:\n",
      "tensor(0.9985, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 51, Neg Train ELBO 4119.056794020124, PriorKL 76.18253227988089, Train MSE 1.1098417889652867, Test MSE 1.2132070271906128\n",
      "Lambda Sq: 3.5673e-07\n",
      "Sigma Sq: 1.1690\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 52, Neg Train ELBO 4132.753774669921, PriorKL 79.09053815399875, Train MSE 1.101238504306023, Test MSE 1.1950480645294086\n",
      "Lambda Sq: 3.5819e-07\n",
      "Sigma Sq: 1.1665\n",
      "Parameter containing:\n",
      "tensor(0.9923, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 53, Neg Train ELBO 4123.438537556278, PriorKL 77.98837596934754, Train MSE 1.1086012264840246, Test MSE 1.2100720033050858\n",
      "Lambda Sq: 3.5675e-07\n",
      "Sigma Sq: 1.1698\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n",
      "Epoch 54, Neg Train ELBO 4111.215087631792, PriorKL 85.91062710809092, Train MSE 1.1030615435331028, Test MSE 1.1953346087159058\n",
      "Lambda Sq: 3.5747e-07\n",
      "Sigma Sq: 1.1667\n",
      "Parameter containing:\n",
      "tensor(0.9905, dtype=torch.float64, requires_grad=True)\n",
      "Epoch 55, Neg Train ELBO 4115.163839604011, PriorKL 81.48509037060194, Train MSE 1.106230008552472, Test MSE 1.2071325736741105\n",
      "Lambda Sq: 3.5858e-07\n",
      "Sigma Sq: 1.1776\n",
      "Parameter containing:\n",
      "tensor(1., dtype=torch.float64, requires_grad=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter scale (Tensor of shape (256,)) of distribution Normal(loc: torch.Size([256]), scale: torch.Size([256])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([0.2134, 0.0637, 0.0341, 0.1736, 0.2258, 0.1781, 0.1566, 0.2153, 0.0917,\n        0.1952, 0.0949, 0.1218, 0.1079, 0.2080, 0.1523, 0.1277, 0.2200,    nan,\n        0.2126, 0.2286, 0.1045, 0.2360, 0.1011, 0.1604, 0.0187, 0.2087, 0.1234,\n        0.0924,    nan, 0.2394, 0.0407, 0.1377, 0.1048, 0.0410, 0.1345, 0.2012,\n        0.2275, 0.1445, 0.1743, 0.2055, 0.0665, 0.1865, 0.1091, 0.1397, 0.1399,\n        0.1407, 0.2157, 0.1841, 0.0830, 0.1611, 0.1287, 0.1384, 0.2148, 0.1534,\n        0.1204, 0.1672, 0.2103, 0.0426, 0.2361, 0.1973, 0.1717, 0.1208, 0.0600,\n        0.1750, 0.1595, 0.2302, 0.0804, 0.1941, 0.2685, 0.1439, 0.0784, 0.2066,\n        0.0713, 0.1413, 0.1231, 0.1986, 0.0732, 0.1241, 0.1308, 0.0226, 0.1724,\n        0.2342, 0.1574, 0.2620, 0.1446, 0.1685, 0.1530, 0.1332, 0.1932, 0.0914,\n           nan, 0.1821, 0.1310, 0.1863, 0.2052, 0.1728, 0.2074, 0.1846, 0.2012,\n        0.1619, 0.1337, 0.1600, 0.2266,    nan, 0.1329, 0.0535, 0.1121, 0.1667,\n        0.1346,    nan, 0.1055, 0.1644, 0.1445, 0.1899, 0.2365, 0.1826, 0.1031,\n        0.2797, 0.1497, 0.1590, 0.1280, 0.1009, 0.1942, 0.2357, 0.1192, 0.2061,\n        0.1877, 0.1850, 0.1029, 0.1110, 0.1785, 0.1302, 0.0653, 0.2315, 0.0826,\n        0.1567, 0.1726, 0.1715, 0.1803, 0.1448, 0.1306, 0.1397, 0.1089, 0.1047,\n        0.3595, 0.2233, 0.2161, 0.0677, 0.1382, 0.2094, 0.1988, 0.0703, 0.2300,\n        0.1929, 0.1190, 0.1484, 0.0714, 0.1244, 0.1868, 0.2348, 0.1648, 0.1576,\n        0.1304, 0.0359, 0.0986, 0.2454, 0.2426, 0.1331, 0.1546, 0.1324, 0.1312,\n        0.1698, 0.1367, 0.2104, 0.1810, 0.1358, 0.1384, 0.2697, 0.1132, 0.2068,\n        0.1645, 0.1450, 0.1610, 0.2327, 0.1521, 0.0828, 0.0906, 0.0863, 0.0459,\n        0.1490, 0.1958, 0.1794, 0.1723, 0.0848, 0.0497, 0.2804, 0.1378, 0.1416,\n        0.2038, 0.2458, 0.0446, 0.1720, 0.1728, 0.1674, 0.1136, 0.1161, 0.1526,\n        0.1388, 0.0884, 0.1511, 0.0650, 0.1406, 0.2239, 0.2252, 0.0342, 0.0354,\n        0.1485, 0.2456, 0.0758, 0.2696, 0.2156, 0.1619, 0.0793, 0.0484, 0.1702,\n        0.1024, 0.0826, 0.1937, 0.3427, 0.1640, 0.1009, 0.1984, 0.1622, 0.1500,\n        0.1467, 0.1895, 0.0737,    nan, 0.0991, 0.0895, 0.1135, 0.1347, 0.0948,\n        0.2136, 0.1338, 0.1944, 0.0848, 0.1518, 0.2205, 0.0768, 0.1096, 0.3377,\n        0.2302, 0.0646, 0.1649, 0.1875], dtype=torch.float64,\n       grad_fn=<SqrtBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# continue training model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m maxEpochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 23\u001b[0m model, nelboList, nllList, klList \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxEpochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43mintervalToPrint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mklList\u001b[39m\u001b[38;5;124m'\u001b[39m: klList\n\u001b[1;32m     32\u001b[0m }, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_and_metrics.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mtrainModel\u001b[0;34m(mod, opt, maxEpochs, batchSize, intervalToPrint)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numBatches):\n\u001b[1;32m     20\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 21\u001b[0m     NLLval \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mbatchSize)\u001b[38;5;241m*\u001b[39m\u001b[43mNLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatchSize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     entVal \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mtrainN)\u001b[38;5;241m*\u001b[39mentropy(mod)\n\u001b[1;32m     23\u001b[0m     ceVal \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mtrainN)\u001b[38;5;241m*\u001b[39mcrossEntropy(mod)\n",
      "Cell \u001b[0;32mIn[2], line 147\u001b[0m, in \u001b[0;36mNLL\u001b[0;34m(mod, startBatch, endBatch)\u001b[0m\n\u001b[1;32m    144\u001b[0m sdB \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(term1 \u001b[38;5;241m+\u001b[39m term2 \u001b[38;5;241m-\u001b[39m term3 \u001b[38;5;241m+\u001b[39m term4)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Sample pre-activation and calculate negative log-likelihood\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m mod\u001b[38;5;241m.\u001b[39mstdNormalDistB \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredMu\u001b[49m\u001b[43m,\u001b[49m\u001b[43msdB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m sampleB \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mstdNormalDistB\u001b[38;5;241m.\u001b[39mrsample()\n\u001b[1;32m    149\u001b[0m trainResiduals \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mY[startBatch:endBatch,:] \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(sampleB,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/distributions/normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNormal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/distributions/distribution.py:56\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 56\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m             )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28msuper\u001b[39m(Distribution, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter scale (Tensor of shape (256,)) of distribution Normal(loc: torch.Size([256]), scale: torch.Size([256])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([0.2134, 0.0637, 0.0341, 0.1736, 0.2258, 0.1781, 0.1566, 0.2153, 0.0917,\n        0.1952, 0.0949, 0.1218, 0.1079, 0.2080, 0.1523, 0.1277, 0.2200,    nan,\n        0.2126, 0.2286, 0.1045, 0.2360, 0.1011, 0.1604, 0.0187, 0.2087, 0.1234,\n        0.0924,    nan, 0.2394, 0.0407, 0.1377, 0.1048, 0.0410, 0.1345, 0.2012,\n        0.2275, 0.1445, 0.1743, 0.2055, 0.0665, 0.1865, 0.1091, 0.1397, 0.1399,\n        0.1407, 0.2157, 0.1841, 0.0830, 0.1611, 0.1287, 0.1384, 0.2148, 0.1534,\n        0.1204, 0.1672, 0.2103, 0.0426, 0.2361, 0.1973, 0.1717, 0.1208, 0.0600,\n        0.1750, 0.1595, 0.2302, 0.0804, 0.1941, 0.2685, 0.1439, 0.0784, 0.2066,\n        0.0713, 0.1413, 0.1231, 0.1986, 0.0732, 0.1241, 0.1308, 0.0226, 0.1724,\n        0.2342, 0.1574, 0.2620, 0.1446, 0.1685, 0.1530, 0.1332, 0.1932, 0.0914,\n           nan, 0.1821, 0.1310, 0.1863, 0.2052, 0.1728, 0.2074, 0.1846, 0.2012,\n        0.1619, 0.1337, 0.1600, 0.2266,    nan, 0.1329, 0.0535, 0.1121, 0.1667,\n        0.1346,    nan, 0.1055, 0.1644, 0.1445, 0.1899, 0.2365, 0.1826, 0.1031,\n        0.2797, 0.1497, 0.1590, 0.1280, 0.1009, 0.1942, 0.2357, 0.1192, 0.2061,\n        0.1877, 0.1850, 0.1029, 0.1110, 0.1785, 0.1302, 0.0653, 0.2315, 0.0826,\n        0.1567, 0.1726, 0.1715, 0.1803, 0.1448, 0.1306, 0.1397, 0.1089, 0.1047,\n        0.3595, 0.2233, 0.2161, 0.0677, 0.1382, 0.2094, 0.1988, 0.0703, 0.2300,\n        0.1929, 0.1190, 0.1484, 0.0714, 0.1244, 0.1868, 0.2348, 0.1648, 0.1576,\n        0.1304, 0.0359, 0.0986, 0.2454, 0.2426, 0.1331, 0.1546, 0.1324, 0.1312,\n        0.1698, 0.1367, 0.2104, 0.1810, 0.1358, 0.1384, 0.2697, 0.1132, 0.2068,\n        0.1645, 0.1450, 0.1610, 0.2327, 0.1521, 0.0828, 0.0906, 0.0863, 0.0459,\n        0.1490, 0.1958, 0.1794, 0.1723, 0.0848, 0.0497, 0.2804, 0.1378, 0.1416,\n        0.2038, 0.2458, 0.0446, 0.1720, 0.1728, 0.1674, 0.1136, 0.1161, 0.1526,\n        0.1388, 0.0884, 0.1511, 0.0650, 0.1406, 0.2239, 0.2252, 0.0342, 0.0354,\n        0.1485, 0.2456, 0.0758, 0.2696, 0.2156, 0.1619, 0.0793, 0.0484, 0.1702,\n        0.1024, 0.0826, 0.1937, 0.3427, 0.1640, 0.1009, 0.1984, 0.1622, 0.1500,\n        0.1467, 0.1895, 0.0737,    nan, 0.0991, 0.0895, 0.1135, 0.1347, 0.0948,\n        0.2136, 0.1338, 0.1944, 0.0848, 0.1518, 0.2205, 0.0768, 0.1096, 0.3377,\n        0.2302, 0.0646, 0.1649, 0.1875], dtype=torch.float64,\n       grad_fn=<SqrtBackward0>)"
     ]
    }
   ],
   "source": [
    "intervalToPrint = 1\n",
    "batchSize = 256\n",
    "numComponents = 16\n",
    "numCESamples = 128\n",
    "numNLLSamples = 2\n",
    "xiVal = 1.0\n",
    "\n",
    "# Load and continue\n",
    "checkpoint = torch.load('model_and_metrics.pt')\n",
    "model = Model(trainFeatures, testFeatures, trainResponse, testResponse, \n",
    "              numComponents, numCESamples, numNLLSamples, xiVal)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "nelboList = checkpoint['nelboList']\n",
    "nllList = checkpoint['nllList']\n",
    "klList = checkpoint['klList']\n",
    "\n",
    "# continue training model\n",
    "maxEpochs = 100\n",
    "model, nelboList, nllList, klList = trainModel(model,optimizer,maxEpochs,batchSize,intervalToPrint)\n",
    "\n",
    "# Save\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'nelboList': nelboList,\n",
    "    'nllList': nllList,\n",
    "    'klList': klList\n",
    "}, 'model_and_metrics.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
